# üìä Bayesian MAP vs Logistic Regression for Binary Classification

[![Made with Python](https://img.shields.io/badge/Made%20with-Python-blue.svg)](https://www.python.org/)
[![Made with Jupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange.svg)](https://jupyter.org/)

This project compares two approaches to binary classification: a **MAP classifier** with known probabilistic distributions, and a **logistic regression model** trained via stochastic gradient descent. It includes analytical derivations, visualizations, Monte Carlo simulations, and performance comparisons.

> üß† This project showcases proficiency in machine learning, statistical modeling, and Python programming. Includes implementation of probabilistic classifiers (MAP, logistic regression), use of stochastic gradient descent, and performance evaluation via Monte Carlo simulation and error metrics.

## üìå Objective

The goal is to analyze and compare two different settings for binary classification:

1. **Case 1 ‚Äì Fully known model**:
   - Derive posterior probabilities analytically.
   - Visualize `p(y=+1 | x)` for different variances (easy vs. difficult classification).
   - Estimate classification error using Monte Carlo simulation for both scenarios.

2. **Case 2 ‚Äì Supervised learning**:
   - Train a logistic regression classifier using stochastic gradient descent (SGD).
   - Estimate classification error empirically using synthetic datasets.
   - Compare performance with the MAP classifier.

## üåç Language Note

All code comments are written in Italian, as this project was originally developed in an academic setting in Italy. Nonetheless, the structure, organization, and methodology follow international best practices in data science and statistical modeling.

The project_brief and the report are available both in English and Italian.

## üõ†Ô∏è Techniques and Methods

- üìà **Bayesian classification** with known priors and Gaussian class-conditionals.
- üß† **Logistic regression** trained with SGD (with and without Monte Carlo averaging).
- üìä **Monte Carlo simulation** for empirical error evaluation.
- üîÅ **Performance analysis** based on varying variance and data richness.

## üß™ Results Summary

- Lower variance leads to sharper posteriors and reduced classification error.
- Logistic regression trained with Monte Carlo-averaged Œ≤ coefficients yields more stable performance.
- As expected, the MAP classifier achieves slightly lower error, especially when data is limited.

## üìÇ Repository Structure

```
üì¶ BAYESIAN-MAP-VS-LOGISTIC-REGRESSION/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ instructions/
‚îÇ   ‚îú‚îÄ‚îÄ project_brief_ENGLISH.pdf
‚îÇ   ‚îî‚îÄ‚îÄ project_brief_ITALIAN.pdf
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ case1_bayesian_map.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ case2_logistic_regression.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üìÅ report/
‚îÇ   ‚îú‚îÄ‚îÄ classification_comparison_ENGLISH.pdf
‚îÇ   ‚îî‚îÄ‚îÄ classification_comparison_ITALIAN.pdf
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md
```

## üìä Technologies Used

- **Language**: Python
- **Environment**: Jupyter Notebook
- **Libraries**: `NumPy`, `Matplotlib`, `SciPy`

## üéì About the Project

This project was created as part of the *Data Science & Data Analysis* course (2024/2025) for the Master‚Äôs Degree in Computer Engineering at the **University of Salerno**.

## üë• Team ‚Äì University of Salerno
    
* [@francescopiocirillo](https://github.com/francescopiocirillo)
    
* [@alefaso-lucky](https://github.com/alefaso-lucky)

## üì¨ Contacts

‚úâÔ∏è Got feedback or want to contribute? Feel free to open an Issue or submit a Pull Request!

## üìà SEO Tags

```
Bayesian classification, logistic regression, MAP estimation, supervised learning, binary classification, statistical modeling, Python, Jupyter Notebook, Monte Carlo simulation, machine learning, pattern recognition, probabilistic models, data science project, AI model comparison, classification algorithms
```

## üìÑ License

This project is licensed under the **MIT License**, a permissive open-source license that allows anyone to use, modify, and distribute the software freely, as long as credit is given and the original license is included.

> In plain terms: **use it, build on it, just don‚Äôt blame us if something breaks**.

> ‚≠ê Like what you see? Consider giving the project a star!
